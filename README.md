# Tweetkind
Twitter Sentiment Analysis with BERT and roBERTa transformers
This project is about the analysis of tweets about coronavirus, with the goal of performing a Sentiment Analysis using BERT and roBERTa algorithms to predict the emotion of a tweet (Positive, Negative or Neutral). In particular, both BERT and ROBERTA will be fine tuned using the given dataset in order to improve the model overall performance.
![image](https://github.com/grv28/Tweetkind/assets/89485172/78669624-052a-4495-8128-f943d9d6e79e)

**Roberta Algorithm:**
Roberta, short for "A Robustly Optimized BERT Pretraining Approach," is a language representation model that builds upon the success of the BERT (Bidirectional Encoder Representations from Transformers) algorithm. Developed by researchers at Facebook AI in 2019, Roberta enhances the original BERT model by introducing modifications in the pretraining process.
BERT Algorithm: BERT, which stands for "Bidirectional Encoder Representations from Transformers," is a groundbreaking language model introduced by researchers at Google AI in 2018. It revolutionized natural language processing (NLP) by leveraging transformer-based architectures and unsupervised learning to capture bidirectional context in text data.
Roberta's modifications in the pretraining process, combined with its larger model size, have resulted in state-of-the-art performance on various benchmark NLP datasets. Its ability to capture deep contextual information has made it a preferred choice for many natural language understanding tasks.

![image](https://github.com/grv28/Tweetkind/assets/89485172/8a0c61ba-fb9c-4e02-ae46-6ac08bc446d3)



