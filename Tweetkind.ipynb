{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grv28/Tweetkind/blob/main/Tweetkind.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Twitter Sentiment Analysis with BERT and roBERTa transformers"
      ],
      "metadata": {
        "id": "mS-jzz6f2PNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgur.com/3tASSmp.jpg\" width=\"700px\">"
      ],
      "metadata": {
        "id": "mFYxlElt2PNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project is about the **analysis of tweets about coronavirus**, with the goal of performing a **Sentiment Analysis using BERT and roBERTa** algorithms to predict the emotion of a tweet (Positive, Negative or Neutral). In particular, both **BERT and ROBERTA will be fine tuned** using the given dataset in order to improve the model overall performance.<br>\n",
        "Before feeding the data to the algorithms, **the tweets will be deeply cleaned to remove links, hashtags at the end of the sentences and punctuation** to allow the algorithms to better understand the text and improve the prediction performance."
      ],
      "metadata": {
        "id": "Xszg1dfp2PNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I performed a similar analysis on non-labeled tweets about Omicron Variant using Vader, NLTK, TextBLOB and Flair NLP algorithms at the following link:\n",
        "- https://www.kaggle.com/ludovicocuoghi/how-are-people-reacting-to-omicron-on-twitter"
      ],
      "metadata": {
        "id": "l2Cv_6rj2PNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis Results:"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-07T16:04:36.962613Z",
          "iopub.execute_input": "2021-12-07T16:04:36.962972Z",
          "iopub.status.idle": "2021-12-07T16:04:36.982915Z",
          "shell.execute_reply.started": "2021-12-07T16:04:36.962881Z",
          "shell.execute_reply": "2021-12-07T16:04:36.982267Z"
        },
        "id": "lupzFUsf2PNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The two algorithms performed quite well on the dataset, showing F1 and accuracy scores around 90%.**<br> Such high scores can only be achieved by performing a good cleaning of the original data, allowing the algorithms to learn the most from it.<br> **In particular, also a baseline Naive Bayes Classifier model has been trained to perform the sentiment classification, with a resulting accuracy and F1 around 70% (much lower than BERT)**.<br>\n",
        "**The training of BERT and roBERTa took around 11 minutes per epoch (for a total of 4 epochs) on GPU** per algorithm, since both **the transformers parameters (more than 100 million) have been fine tuned** to perform the best on the given dataset. It is possible to train only the last layer of the transformer without fine tuning the other parameters: however, this usually leads to inferior results compared to the fine tuning approach."
      ],
      "metadata": {
        "id": "mLTKFnzX2PNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgur.com/htll3Fu.png\" width=\"900px\">"
      ],
      "metadata": {
        "id": "jlPaggqh2PNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:17.778826Z",
          "iopub.execute_input": "2021-12-22T21:15:17.779154Z",
          "iopub.status.idle": "2021-12-22T21:15:17.789097Z",
          "shell.execute_reply.started": "2021-12-22T21:15:17.779117Z",
          "shell.execute_reply": "2021-12-22T21:15:17.788146Z"
        },
        "trusted": true,
        "id": "bs2BOU662PNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#general purpose packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#data processing\n",
        "import re, string\n",
        "import emoji\n",
        "import nltk\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#Naive Bayes\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#transformers\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import TFBertModel\n",
        "from transformers import RobertaTokenizerFast\n",
        "from transformers import TFRobertaModel\n",
        "\n",
        "#keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "#metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#set seed for reproducibility\n",
        "seed=42\n",
        "\n",
        "#set style for plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.despine()\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "plt.rc(\"figure\", autolayout=True)\n",
        "plt.rc(\"axes\", labelweight=\"bold\", labelsize=\"large\", titleweight=\"bold\", titlepad=10)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:17.791452Z",
          "iopub.execute_input": "2021-12-22T21:15:17.791721Z",
          "iopub.status.idle": "2021-12-22T21:15:17.808398Z",
          "shell.execute_reply.started": "2021-12-22T21:15:17.791678Z",
          "shell.execute_reply": "2021-12-22T21:15:17.807697Z"
        },
        "trusted": true,
        "id": "G9Yif-yv2PNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EF1-JNkr2PNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A8_uAKQJ2PNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom functions definition:"
      ],
      "metadata": {
        "id": "ZbwTjxfm2PNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conf_matrix(y, y_pred, title):\n",
        "    fig, ax =plt.subplots(figsize=(5,5))\n",
        "    labels=['Negative', 'Neutral', 'Positive']\n",
        "    ax=sns.heatmap(confusion_matrix(y, y_pred), annot=True, cmap=\"Blues\", fmt='g', cbar=False, annot_kws={\"size\":25})\n",
        "    plt.title(title, fontsize=20)\n",
        "    ax.xaxis.set_ticklabels(labels, fontsize=17)\n",
        "    ax.yaxis.set_ticklabels(labels, fontsize=17)\n",
        "    ax.set_ylabel('Test', fontsize=20)\n",
        "    ax.set_xlabel('Predicted', fontsize=20)\n",
        "    plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:17.809938Z",
          "iopub.execute_input": "2021-12-22T21:15:17.810284Z",
          "iopub.status.idle": "2021-12-22T21:15:17.817316Z",
          "shell.execute_reply.started": "2021-12-22T21:15:17.810234Z",
          "shell.execute_reply": "2021-12-22T21:15:17.816401Z"
        },
        "trusted": true,
        "id": "24-291952PNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the data"
      ],
      "metadata": {
        "id": "PK-HPpv32PNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_train.csv',encoding='ISO-8859-1')\n",
        "df_test = pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_test.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:17.818782Z",
          "iopub.execute_input": "2021-12-22T21:15:17.819093Z",
          "iopub.status.idle": "2021-12-22T21:15:17.964962Z",
          "shell.execute_reply.started": "2021-12-22T21:15:17.819059Z",
          "shell.execute_reply": "2021-12-22T21:15:17.964233Z"
        },
        "trusted": true,
        "id": "wLV0Ea7Z2PNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: UTF-8 encoding does not work on the dataset when loading it with pandas 'read_csv' function. This lead to the use of 'ISO-8859-1'/latin-1 encoding. <br>\n",
        "It will be found later that some special characters like apostrophes are turned into '\\x92', which will be taken care of during the data cleaning process.\n",
        "                                                                                                         "
      ],
      "metadata": {
        "id": "sSog0OJv2PNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:17.967262Z",
          "iopub.execute_input": "2021-12-22T21:15:17.967557Z",
          "iopub.status.idle": "2021-12-22T21:15:17.979179Z",
          "shell.execute_reply.started": "2021-12-22T21:15:17.967519Z",
          "shell.execute_reply": "2021-12-22T21:15:17.978344Z"
        },
        "trusted": true,
        "id": "hfhkQeTK2PNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:17.980745Z",
          "iopub.execute_input": "2021-12-22T21:15:17.981042Z",
          "iopub.status.idle": "2021-12-22T21:15:18.011269Z",
          "shell.execute_reply.started": "2021-12-22T21:15:17.981005Z",
          "shell.execute_reply": "2021-12-22T21:15:18.010543Z"
        },
        "trusted": true,
        "id": "t8hpRFxH2PNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We convert the date column 'TweetAt' to pandas datetime format to improve its usability in the further analysis."
      ],
      "metadata": {
        "id": "GYj2upZ42PNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['TweetAt'] = pd.to_datetime(df['TweetAt'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:18.012419Z",
          "iopub.execute_input": "2021-12-22T21:15:18.012651Z",
          "iopub.status.idle": "2021-12-22T21:15:18.025611Z",
          "shell.execute_reply.started": "2021-12-22T21:15:18.012618Z",
          "shell.execute_reply": "2021-12-22T21:15:18.024835Z"
        },
        "trusted": true,
        "id": "xSgKoaMQ2PNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Duplicate tweets?"
      ],
      "metadata": {
        "id": "kETfAAv82PNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(subset='OriginalTweet',inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:18.026722Z",
          "iopub.execute_input": "2021-12-22T21:15:18.027027Z",
          "iopub.status.idle": "2021-12-22T21:15:18.067792Z",
          "shell.execute_reply.started": "2021-12-22T21:15:18.026991Z",
          "shell.execute_reply": "2021-12-22T21:15:18.067127Z"
        },
        "trusted": true,
        "id": "c2Izk1Dw2PNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:18.069027Z",
          "iopub.execute_input": "2021-12-22T21:15:18.069285Z",
          "iopub.status.idle": "2021-12-22T21:15:18.094153Z",
          "shell.execute_reply.started": "2021-12-22T21:15:18.069251Z",
          "shell.execute_reply": "2021-12-22T21:15:18.092972Z"
        },
        "trusted": true,
        "id": "18zist4v2PNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good news, No duplicate tweets !"
      ],
      "metadata": {
        "id": "DSQm7F8j2PNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tweets count by date"
      ],
      "metadata": {
        "id": "Soto44av2PNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_per_day = df['TweetAt'].dt.strftime('%m-%d').value_counts().sort_index().reset_index(name='counts')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:18.096834Z",
          "iopub.execute_input": "2021-12-22T21:15:18.097078Z",
          "iopub.status.idle": "2021-12-22T21:15:18.380865Z",
          "shell.execute_reply.started": "2021-12-22T21:15:18.097047Z",
          "shell.execute_reply": "2021-12-22T21:15:18.380184Z"
        },
        "trusted": true,
        "id": "qBVQ9v6F2PNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "ax = sns.barplot(x='index', y='counts', data=tweets_per_day,edgecolor = 'black',ci=False, palette='Blues_r')\n",
        "plt.title('Tweets count by date')\n",
        "plt.yticks([])\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:18.383206Z",
          "iopub.execute_input": "2021-12-22T21:15:18.383812Z",
          "iopub.status.idle": "2021-12-22T21:15:19.037172Z",
          "shell.execute_reply.started": "2021-12-22T21:15:18.383781Z",
          "shell.execute_reply": "2021-12-22T21:15:19.036514Z"
        },
        "trusted": true,
        "id": "6H-7IdGe2PNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We notice that in the dataset there are some days without tweets in the dataset. Among the days with tweets, most of them are made around the end of March: from 18th of Match to the 26th of March."
      ],
      "metadata": {
        "id": "WR__91j42PNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tweets per country and city"
      ],
      "metadata": {
        "id": "E5if0sJj2PNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_per_country = df['Location'].value_counts().loc[lambda x : x > 100].reset_index(name='counts')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:19.038417Z",
          "iopub.execute_input": "2021-12-22T21:15:19.038736Z",
          "iopub.status.idle": "2021-12-22T21:15:19.054194Z",
          "shell.execute_reply.started": "2021-12-22T21:15:19.038697Z",
          "shell.execute_reply": "2021-12-22T21:15:19.053557Z"
        },
        "trusted": true,
        "id": "1fq3kyRI2PNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "ax = sns.barplot(x='index', y='counts', data=tweets_per_country,edgecolor = 'black',ci=False, palette='Spectral')\n",
        "plt.title('Tweets count by country')\n",
        "plt.xticks(rotation=70)\n",
        "plt.yticks([])\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:19.055623Z",
          "iopub.execute_input": "2021-12-22T21:15:19.05591Z",
          "iopub.status.idle": "2021-12-22T21:15:19.664941Z",
          "shell.execute_reply.started": "2021-12-22T21:15:19.055874Z",
          "shell.execute_reply": "2021-12-22T21:15:19.664287Z"
        },
        "trusted": true,
        "id": "l_4gH_Pd2PNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'location' column contains both countries and cities. It could be interesting to separate cities and countries, however this wont be investigated in this work."
      ],
      "metadata": {
        "id": "uFWYDxb52PNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tweets Deep Cleaning"
      ],
      "metadata": {
        "id": "NmGA_J-J2PNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following, we will perform some data cleaning on the raw text of the tweets.<br>\n",
        "To simplify the analaysis, we will just keep the columns 'Originaltweet' (raw tweets) and the target column 'Sentiment'."
      ],
      "metadata": {
        "id": "HXjnIH0v2PNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['OriginalTweet','Sentiment']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:19.666416Z",
          "iopub.execute_input": "2021-12-22T21:15:19.666889Z",
          "iopub.status.idle": "2021-12-22T21:15:19.674072Z",
          "shell.execute_reply.started": "2021-12-22T21:15:19.66685Z",
          "shell.execute_reply": "2021-12-22T21:15:19.673268Z"
        },
        "trusted": true,
        "id": "uoRfCtA52PNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_test[['OriginalTweet','Sentiment']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:19.675524Z",
          "iopub.execute_input": "2021-12-22T21:15:19.675834Z",
          "iopub.status.idle": "2021-12-22T21:15:19.685079Z",
          "shell.execute_reply.started": "2021-12-22T21:15:19.675777Z",
          "shell.execute_reply": "2021-12-22T21:15:19.684432Z"
        },
        "trusted": true,
        "id": "ysX35Bod2PNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Then we define custom functions to clean the text of the tweets.**"
      ],
      "metadata": {
        "id": "GciXReqZ2PNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##CUSTOM DEFINED FUNCTIONS TO CLEAN THE TWEETS\n",
        "\n",
        "#Clean emojis from text\n",
        "def strip_emoji(text):\n",
        "    return re.sub(emoji.get_emoji_regexp(), r\"\", text) #remove emoji\n",
        "\n",
        "#Remove punctuations, links, mentions and \\r\\n new line characters\n",
        "def strip_all_entities(text):\n",
        "    text = text.replace('\\r', '').replace('\\n', ' ').replace('\\n', ' ').lower() #remove \\n and \\r and lowercase\n",
        "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text) #remove links and mentions\n",
        "    text = re.sub(r'[^\\x00-\\x7f]',r'', text) #remove non utf8/ascii characters such as '\\x9a\\x91\\x97\\x9a\\x97'\n",
        "    banned_list= string.punctuation + 'Ã'+'±'+'ã'+'¼'+'â'+'»'+'§'\n",
        "    table = str.maketrans('', '', banned_list)\n",
        "    text = text.translate(table)\n",
        "    return text\n",
        "\n",
        "#clean hashtags at the end of the sentence, and keep those in the middle of the sentence by removing just the # symbol\n",
        "def clean_hashtags(tweet):\n",
        "    new_tweet = \" \".join(word.strip() for word in re.split('#(?!(?:hashtag)\\b)[\\w-]+(?=(?:\\s+#[\\w-]+)*\\s*$)', tweet)) #remove last hashtags\n",
        "    new_tweet2 = \" \".join(word.strip() for word in re.split('#|_', new_tweet)) #remove hashtags symbol from words in the middle of the sentence\n",
        "    return new_tweet2\n",
        "\n",
        "#Filter special characters such as & and $ present in some words\n",
        "def filter_chars(a):\n",
        "    sent = []\n",
        "    for word in a.split(' '):\n",
        "        if ('$' in word) | ('&' in word):\n",
        "            sent.append('')\n",
        "        else:\n",
        "            sent.append(word)\n",
        "    return ' '.join(sent)\n",
        "\n",
        "def remove_mult_spaces(text): # remove multiple spaces\n",
        "    return re.sub(\"\\s\\s+\" , \" \", text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:19.687068Z",
          "iopub.execute_input": "2021-12-22T21:15:19.687746Z",
          "iopub.status.idle": "2021-12-22T21:15:19.698296Z",
          "shell.execute_reply.started": "2021-12-22T21:15:19.687704Z",
          "shell.execute_reply": "2021-12-22T21:15:19.697572Z"
        },
        "trusted": true,
        "id": "7YuwwxGk2PNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts_new = []\n",
        "for t in df.OriginalTweet:\n",
        "    texts_new.append(remove_mult_spaces(filter_chars(clean_hashtags(strip_all_entities(strip_emoji(t))))))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:15:19.701015Z",
          "iopub.execute_input": "2021-12-22T21:15:19.701235Z",
          "iopub.status.idle": "2021-12-22T21:16:17.869828Z",
          "shell.execute_reply.started": "2021-12-22T21:15:19.701201Z",
          "shell.execute_reply": "2021-12-22T21:16:17.869039Z"
        },
        "trusted": true,
        "id": "c25EMspc2PNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts_new_test = []\n",
        "for t in df_test.OriginalTweet:\n",
        "    texts_new_test.append(remove_mult_spaces(filter_chars(clean_hashtags(strip_all_entities(strip_emoji(t))))))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:17.871222Z",
          "iopub.execute_input": "2021-12-22T21:16:17.871709Z",
          "iopub.status.idle": "2021-12-22T21:16:23.197999Z",
          "shell.execute_reply.started": "2021-12-22T21:16:17.871667Z",
          "shell.execute_reply": "2021-12-22T21:16:23.197295Z"
        },
        "trusted": true,
        "id": "-essdNQL2PNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can create a new column, for both train and test sets, to host the cleaned version of the tweets' text."
      ],
      "metadata": {
        "id": "2hNLA4FH2PNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_clean'] = texts_new\n",
        "df_test['text_clean'] = texts_new_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.199371Z",
          "iopub.execute_input": "2021-12-22T21:16:23.199648Z",
          "iopub.status.idle": "2021-12-22T21:16:23.212118Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.199614Z",
          "shell.execute_reply": "2021-12-22T21:16:23.211257Z"
        },
        "trusted": true,
        "id": "pnatRbp92PNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_clean'].head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.213498Z",
          "iopub.execute_input": "2021-12-22T21:16:23.213745Z",
          "iopub.status.idle": "2021-12-22T21:16:23.227327Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.213708Z",
          "shell.execute_reply": "2021-12-22T21:16:23.226641Z"
        },
        "trusted": true,
        "id": "unvkNSnp2PNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['text_clean'].head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.232295Z",
          "iopub.execute_input": "2021-12-22T21:16:23.232676Z",
          "iopub.status.idle": "2021-12-22T21:16:23.239727Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.232647Z",
          "shell.execute_reply": "2021-12-22T21:16:23.239023Z"
        },
        "trusted": true,
        "id": "YM0M_9DV2PNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_clean'][1:8].values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.241001Z",
          "iopub.execute_input": "2021-12-22T21:16:23.241499Z",
          "iopub.status.idle": "2021-12-22T21:16:23.250236Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.241461Z",
          "shell.execute_reply": "2021-12-22T21:16:23.249487Z"
        },
        "trusted": true,
        "id": "xNfH7Gki2PNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moreover, we will also create a column to host the lenght of the cleaned text, to check if by cleaning the text we removed too much text or almost entirely the tweet!"
      ],
      "metadata": {
        "id": "xykfJYCM2PN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_len = []\n",
        "for text in df.text_clean:\n",
        "    tweet_len = len(text.split())\n",
        "    text_len.append(tweet_len)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.252435Z",
          "iopub.execute_input": "2021-12-22T21:16:23.253023Z",
          "iopub.status.idle": "2021-12-22T21:16:23.346853Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.252986Z",
          "shell.execute_reply": "2021-12-22T21:16:23.346251Z"
        },
        "trusted": true,
        "id": "Dwjokxki2PN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_len'] = text_len"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.347901Z",
          "iopub.execute_input": "2021-12-22T21:16:23.348129Z",
          "iopub.status.idle": "2021-12-22T21:16:23.369365Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.348096Z",
          "shell.execute_reply": "2021-12-22T21:16:23.368729Z"
        },
        "trusted": true,
        "id": "ESG2fb5g2PN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_len_test = []\n",
        "for text in df_test.text_clean:\n",
        "    tweet_len = len(text.split())\n",
        "    text_len_test.append(tweet_len)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.370787Z",
          "iopub.execute_input": "2021-12-22T21:16:23.371086Z",
          "iopub.status.idle": "2021-12-22T21:16:23.387455Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.371047Z",
          "shell.execute_reply": "2021-12-22T21:16:23.386622Z"
        },
        "trusted": true,
        "id": "KTnPtZWW2PN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['text_len'] = text_len_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.388853Z",
          "iopub.execute_input": "2021-12-22T21:16:23.38944Z",
          "iopub.status.idle": "2021-12-22T21:16:23.398823Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.389402Z",
          "shell.execute_reply": "2021-12-22T21:16:23.398101Z"
        },
        "trusted": true,
        "id": "6V6ybTK22PN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "ax = sns.countplot(x='text_len', data=df[df['text_len']<10], palette='mako')\n",
        "plt.title('Training tweets with less than 10 words')\n",
        "plt.yticks([])\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.400127Z",
          "iopub.execute_input": "2021-12-22T21:16:23.400721Z",
          "iopub.status.idle": "2021-12-22T21:16:23.670878Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.400676Z",
          "shell.execute_reply": "2021-12-22T21:16:23.67021Z"
        },
        "trusted": true,
        "id": "6GMuVOVW2PN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "ax = sns.countplot(x='text_len', data=df_test[df_test['text_len']<10], palette='mako')\n",
        "plt.title('Test tweets with less than 10 words')\n",
        "plt.yticks([])\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.672187Z",
          "iopub.execute_input": "2021-12-22T21:16:23.672665Z",
          "iopub.status.idle": "2021-12-22T21:16:23.926009Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.672624Z",
          "shell.execute_reply": "2021-12-22T21:16:23.925218Z"
        },
        "trusted": true,
        "id": "A5TMtz7g2PN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, there are lots of cleaned tweets with 0 words: this is due to the cleaning performed before. This means that some tweets contained only mentions, hashtags and links, which have been removed. We will drop these empty tweets and also those with less than 5 words."
      ],
      "metadata": {
        "id": "M2pbJzVK2PN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" DF SHAPE: {df.shape}\")\n",
        "print(f\" DF TEST SHAPE: {df_test.shape}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.927254Z",
          "iopub.execute_input": "2021-12-22T21:16:23.927515Z",
          "iopub.status.idle": "2021-12-22T21:16:23.935987Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.92748Z",
          "shell.execute_reply": "2021-12-22T21:16:23.935269Z"
        },
        "trusted": true,
        "id": "O2IiHNfp2PN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['text_len'] > 4]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.937463Z",
          "iopub.execute_input": "2021-12-22T21:16:23.937742Z",
          "iopub.status.idle": "2021-12-22T21:16:23.947934Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.937695Z",
          "shell.execute_reply": "2021-12-22T21:16:23.947188Z"
        },
        "trusted": true,
        "id": "68u1T8b22PN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_test[df_test['text_len'] > 4]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.949457Z",
          "iopub.execute_input": "2021-12-22T21:16:23.949722Z",
          "iopub.status.idle": "2021-12-22T21:16:23.956516Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.949679Z",
          "shell.execute_reply": "2021-12-22T21:16:23.955817Z"
        },
        "trusted": true,
        "id": "rIKI9Sqs2PN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" DF SHAPE: {df.shape}\")\n",
        "print(f\" DF TEST SHAPE: {df_test.shape}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.957889Z",
          "iopub.execute_input": "2021-12-22T21:16:23.958147Z",
          "iopub.status.idle": "2021-12-22T21:16:23.965132Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.958113Z",
          "shell.execute_reply": "2021-12-22T21:16:23.964401Z"
        },
        "trusted": true,
        "id": "dHqxotGu2PN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training data deeper cleaning"
      ],
      "metadata": {
        "id": "InmPwI662PN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's perform a further cleaning checking the tokenizer version of the sentences."
      ],
      "metadata": {
        "id": "DP5iRoZS2PN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we import the BERT tokenizer."
      ],
      "metadata": {
        "id": "1ZsiZ76g2PN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:23.966349Z",
          "iopub.execute_input": "2021-12-22T21:16:23.966874Z",
          "iopub.status.idle": "2021-12-22T21:16:30.505565Z",
          "shell.execute_reply.started": "2021-12-22T21:16:23.966837Z",
          "shell.execute_reply": "2021-12-22T21:16:30.504847Z"
        },
        "trusted": true,
        "id": "rhIEOLtE2PN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in df['text_clean'].values:\n",
        "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
        "    token_lens.append(len(tokens))\n",
        "\n",
        "max_len=np.max(token_lens)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:30.506822Z",
          "iopub.execute_input": "2021-12-22T21:16:30.507117Z",
          "iopub.status.idle": "2021-12-22T21:16:38.608135Z",
          "shell.execute_reply.started": "2021-12-22T21:16:30.507082Z",
          "shell.execute_reply": "2021-12-22T21:16:38.60725Z"
        },
        "trusted": true,
        "id": "J2P4D5QN2PN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MAX TOKENIZED SENTENCE LENGTH: {max_len}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:38.612489Z",
          "iopub.execute_input": "2021-12-22T21:16:38.614497Z",
          "iopub.status.idle": "2021-12-22T21:16:38.622543Z",
          "shell.execute_reply.started": "2021-12-22T21:16:38.614458Z",
          "shell.execute_reply": "2021-12-22T21:16:38.621788Z"
        },
        "trusted": true,
        "id": "e0XwvmB_2PN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the long tokenized sentences (with more than 80 tokens ):"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-07T12:49:48.842045Z",
          "iopub.execute_input": "2021-12-07T12:49:48.842301Z",
          "iopub.status.idle": "2021-12-07T12:49:48.848445Z",
          "shell.execute_reply.started": "2021-12-07T12:49:48.842267Z",
          "shell.execute_reply": "2021-12-07T12:49:48.847098Z"
        },
        "id": "vI5kgVLP2PN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_lens = []\n",
        "\n",
        "for i,txt in enumerate(df['text_clean'].values):\n",
        "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
        "    token_lens.append(len(tokens))\n",
        "    if len(tokens)>80:\n",
        "        print(f\"INDEX: {i}, TEXT: {txt}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:38.627275Z",
          "iopub.execute_input": "2021-12-22T21:16:38.627927Z",
          "iopub.status.idle": "2021-12-22T21:16:45.918973Z",
          "shell.execute_reply.started": "2021-12-22T21:16:38.62789Z",
          "shell.execute_reply": "2021-12-22T21:16:45.918256Z"
        },
        "trusted": true,
        "id": "bM7nJKPW2PN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These sentences are not in english. They should be dropped."
      ],
      "metadata": {
        "id": "XLqWB8uH2PN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['token_lens'] = token_lens"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:45.920127Z",
          "iopub.execute_input": "2021-12-22T21:16:45.920514Z",
          "iopub.status.idle": "2021-12-22T21:16:45.942482Z",
          "shell.execute_reply.started": "2021-12-22T21:16:45.920472Z",
          "shell.execute_reply": "2021-12-22T21:16:45.941845Z"
        },
        "trusted": true,
        "id": "pvs2PbfA2PN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values(by='token_lens', ascending=False)\n",
        "df.head(20)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:45.943569Z",
          "iopub.execute_input": "2021-12-22T21:16:45.943812Z",
          "iopub.status.idle": "2021-12-22T21:16:45.966583Z",
          "shell.execute_reply.started": "2021-12-22T21:16:45.943779Z",
          "shell.execute_reply": "2021-12-22T21:16:45.965943Z"
        },
        "trusted": true,
        "id": "IGY4bOYR2PN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[12:]\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:45.967696Z",
          "iopub.execute_input": "2021-12-22T21:16:45.968414Z",
          "iopub.status.idle": "2021-12-22T21:16:45.980023Z",
          "shell.execute_reply.started": "2021-12-22T21:16:45.968366Z",
          "shell.execute_reply": "2021-12-22T21:16:45.97925Z"
        },
        "trusted": true,
        "id": "B6GYuouo2PN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset looks more clean now. We will shuffle it and reset the index."
      ],
      "metadata": {
        "id": "lRis301F2PN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:45.981284Z",
          "iopub.execute_input": "2021-12-22T21:16:45.98155Z",
          "iopub.status.idle": "2021-12-22T21:16:45.995008Z",
          "shell.execute_reply.started": "2021-12-22T21:16:45.981515Z",
          "shell.execute_reply": "2021-12-22T21:16:45.994358Z"
        },
        "trusted": true,
        "id": "e0M7GNjB2PN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test data deeper cleaning"
      ],
      "metadata": {
        "id": "moLB81852PN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will perform the data cleaning based on the tokenized sentences on the test set."
      ],
      "metadata": {
        "id": "LR0u_g2b2PN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_lens_test = []\n",
        "\n",
        "for txt in df_test['text_clean'].values:\n",
        "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
        "    token_lens_test.append(len(tokens))\n",
        "\n",
        "max_len=np.max(token_lens_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:45.996245Z",
          "iopub.execute_input": "2021-12-22T21:16:45.996503Z",
          "iopub.status.idle": "2021-12-22T21:16:46.749676Z",
          "shell.execute_reply.started": "2021-12-22T21:16:45.996467Z",
          "shell.execute_reply": "2021-12-22T21:16:46.748944Z"
        },
        "trusted": true,
        "id": "V3LhPEK72PN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MAX TOKENIZED SENTENCE LENGTH: {max_len}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:46.75107Z",
          "iopub.execute_input": "2021-12-22T21:16:46.751349Z",
          "iopub.status.idle": "2021-12-22T21:16:46.756497Z",
          "shell.execute_reply.started": "2021-12-22T21:16:46.751312Z",
          "shell.execute_reply": "2021-12-22T21:16:46.755793Z"
        },
        "trusted": true,
        "id": "jRw17i_p2PN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_lens_test = []\n",
        "\n",
        "for i,txt in enumerate(df_test['text_clean'].values):\n",
        "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
        "    token_lens_test.append(len(tokens))\n",
        "    if len(tokens)>80:\n",
        "        print(f\"INDEX: {i}, TEXT: {txt}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:46.757831Z",
          "iopub.execute_input": "2021-12-22T21:16:46.758342Z",
          "iopub.status.idle": "2021-12-22T21:16:47.500654Z",
          "shell.execute_reply.started": "2021-12-22T21:16:46.758304Z",
          "shell.execute_reply": "2021-12-22T21:16:47.499983Z"
        },
        "trusted": true,
        "id": "pXlv4YxQ2PN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['token_lens'] = token_lens_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.501809Z",
          "iopub.execute_input": "2021-12-22T21:16:47.50205Z",
          "iopub.status.idle": "2021-12-22T21:16:47.508688Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.502016Z",
          "shell.execute_reply": "2021-12-22T21:16:47.50766Z"
        },
        "trusted": true,
        "id": "IPZSSm972PN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_test.sort_values(by='token_lens', ascending=False)\n",
        "df_test.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.509929Z",
          "iopub.execute_input": "2021-12-22T21:16:47.510349Z",
          "iopub.status.idle": "2021-12-22T21:16:47.527481Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.510311Z",
          "shell.execute_reply": "2021-12-22T21:16:47.526777Z"
        },
        "trusted": true,
        "id": "VGzQrGZ72PN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_test.iloc[5:]\n",
        "df_test.head(3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.528747Z",
          "iopub.execute_input": "2021-12-22T21:16:47.529191Z",
          "iopub.status.idle": "2021-12-22T21:16:47.539778Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.529156Z",
          "shell.execute_reply": "2021-12-22T21:16:47.539121Z"
        },
        "trusted": true,
        "id": "YYkrd9t_2PN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_test.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.541138Z",
          "iopub.execute_input": "2021-12-22T21:16:47.541731Z",
          "iopub.status.idle": "2021-12-22T21:16:47.548553Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.541662Z",
          "shell.execute_reply": "2021-12-22T21:16:47.547872Z"
        },
        "trusted": true,
        "id": "WHtrdJvr2PN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the data cleaning is completed. I will perform more data cleaning if I have new ideas !! :)"
      ],
      "metadata": {
        "id": "KsQQRpGx2PN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment column analysis"
      ],
      "metadata": {
        "id": "5k5DXLC82PN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will look at the target column 'Sentiment'."
      ],
      "metadata": {
        "id": "7Dsx_ZfK2PN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.549868Z",
          "iopub.execute_input": "2021-12-22T21:16:47.550374Z",
          "iopub.status.idle": "2021-12-22T21:16:47.564332Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.550336Z",
          "shell.execute_reply": "2021-12-22T21:16:47.56366Z"
        },
        "trusted": true,
        "id": "hsM044-X2PN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing we can do is to encode the categories with numbers. We will also create just 3 possible emotions: Positive, Neutral and Negative."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-05T11:35:57.747932Z",
          "iopub.execute_input": "2021-12-05T11:35:57.748569Z",
          "iopub.status.idle": "2021-12-05T11:35:57.753489Z",
          "shell.execute_reply.started": "2021-12-05T11:35:57.748528Z",
          "shell.execute_reply": "2021-12-05T11:35:57.752685Z"
        },
        "id": "xBHhGcRO2PN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'] = df['Sentiment'].map({'Extremely Negative':0,'Negative':0,'Neutral':1,'Positive':2,'Extremely Positive':2})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.565714Z",
          "iopub.execute_input": "2021-12-22T21:16:47.566009Z",
          "iopub.status.idle": "2021-12-22T21:16:47.580459Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.565975Z",
          "shell.execute_reply": "2021-12-22T21:16:47.579684Z"
        },
        "trusted": true,
        "id": "gAj4cpHF2PN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['Sentiment'] = df_test['Sentiment'].map({'Extremely Negative':0,'Negative':0,'Neutral':1,'Positive':2,'Extremely Positive':2})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.581764Z",
          "iopub.execute_input": "2021-12-22T21:16:47.582551Z",
          "iopub.status.idle": "2021-12-22T21:16:47.589144Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.582474Z",
          "shell.execute_reply": "2021-12-22T21:16:47.588501Z"
        },
        "trusted": true,
        "id": "hHuKW2Ad2PN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.591248Z",
          "iopub.execute_input": "2021-12-22T21:16:47.592996Z",
          "iopub.status.idle": "2021-12-22T21:16:47.599802Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.592966Z",
          "shell.execute_reply": "2021-12-22T21:16:47.59916Z"
        },
        "trusted": true,
        "id": "4jQZQang2PN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We note that the three classes are imbalanced. We will proceed with oversampling the train test, to remove bias towards the majority classes."
      ],
      "metadata": {
        "id": "p1TZZ7uW2PN5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class Balancing by RandomOverSampler"
      ],
      "metadata": {
        "id": "_OGyUEOU2PN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler()\n",
        "train_x, train_y = ros.fit_resample(np.array(df['text_clean']).reshape(-1, 1), np.array(df['Sentiment']).reshape(-1, 1));\n",
        "train_os = pd.DataFrame(list(zip([x[0] for x in train_x], train_y)), columns = ['text_clean', 'Sentiment']);"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.601159Z",
          "iopub.execute_input": "2021-12-22T21:16:47.601752Z",
          "iopub.status.idle": "2021-12-22T21:16:47.697589Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.601678Z",
          "shell.execute_reply": "2021-12-22T21:16:47.696904Z"
        },
        "trusted": true,
        "id": "Uao0OOpT2PN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_os['Sentiment'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.698691Z",
          "iopub.execute_input": "2021-12-22T21:16:47.698926Z",
          "iopub.status.idle": "2021-12-22T21:16:47.705998Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.698894Z",
          "shell.execute_reply": "2021-12-22T21:16:47.70527Z"
        },
        "trusted": true,
        "id": "5C4KWLDo2PN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train - Validation - Test split"
      ],
      "metadata": {
        "id": "hlGmqCdR2PN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_os['text_clean'].values\n",
        "y = train_os['Sentiment'].values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.713125Z",
          "iopub.execute_input": "2021-12-22T21:16:47.713316Z",
          "iopub.status.idle": "2021-12-22T21:16:47.717547Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.713294Z",
          "shell.execute_reply": "2021-12-22T21:16:47.716647Z"
        },
        "trusted": true,
        "id": "4k-vCe1n2PN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A validation set will be extracted from the training set to monitor the validation accuracy, and so prevent overfitting."
      ],
      "metadata": {
        "id": "_L0SQtiq2PN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, stratify=y, random_state=seed)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.718981Z",
          "iopub.execute_input": "2021-12-22T21:16:47.719469Z",
          "iopub.status.idle": "2021-12-22T21:16:47.761536Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.719431Z",
          "shell.execute_reply": "2021-12-22T21:16:47.760925Z"
        },
        "trusted": true,
        "id": "1Pg6jlbq2PN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = df_test['text_clean'].values\n",
        "y_test = df_test['Sentiment'].values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.762757Z",
          "iopub.execute_input": "2021-12-22T21:16:47.763Z",
          "iopub.status.idle": "2021-12-22T21:16:47.768878Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.762967Z",
          "shell.execute_reply": "2021-12-22T21:16:47.76812Z"
        },
        "trusted": true,
        "id": "27nqlxhr2PN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One hot encoding"
      ],
      "metadata": {
        "id": "clUxlgni2PN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After performing some tests, by using one hot encoding on the target variable we achieved higher accuracy. For this reason we will choose one hot enconding over label encoding. <br>\n",
        "EDIT: We will save a copy of the label encoded target columns since they could be useful for further analysis."
      ],
      "metadata": {
        "id": "YDL887Pa2PN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_le = y_train.copy()\n",
        "y_valid_le = y_valid.copy()\n",
        "y_test_le = y_test.copy()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.770333Z",
          "iopub.execute_input": "2021-12-22T21:16:47.770915Z",
          "iopub.status.idle": "2021-12-22T21:16:47.776791Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.770878Z",
          "shell.execute_reply": "2021-12-22T21:16:47.776179Z"
        },
        "trusted": true,
        "id": "8aSNIpAa2PN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ohe = preprocessing.OneHotEncoder()\n",
        "y_train = ohe.fit_transform(np.array(y_train).reshape(-1, 1)).toarray()\n",
        "y_valid = ohe.fit_transform(np.array(y_valid).reshape(-1, 1)).toarray()\n",
        "y_test = ohe.fit_transform(np.array(y_test).reshape(-1, 1)).toarray()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.778211Z",
          "iopub.execute_input": "2021-12-22T21:16:47.778775Z",
          "iopub.status.idle": "2021-12-22T21:16:47.791468Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.778739Z",
          "shell.execute_reply": "2021-12-22T21:16:47.790847Z"
        },
        "trusted": true,
        "id": "nY2QeXS02PN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"TRAINING DATA: {X_train.shape[0]}\\nVALIDATION DATA: {X_valid.shape[0]}\\nTESTING DATA: {X_test.shape[0]}\" )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.792606Z",
          "iopub.execute_input": "2021-12-22T21:16:47.792855Z",
          "iopub.status.idle": "2021-12-22T21:16:47.797366Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.792822Z",
          "shell.execute_reply": "2021-12-22T21:16:47.796422Z"
        },
        "trusted": true,
        "id": "dzRX7DXr2PN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline model: Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "BCLW35th2PN7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before implementing BERT, we will define a simple Naive Bayes baseline model to classify the tweets."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T19:59:56.681677Z",
          "iopub.execute_input": "2021-12-22T19:59:56.68241Z",
          "iopub.status.idle": "2021-12-22T19:59:56.711837Z",
          "shell.execute_reply.started": "2021-12-22T19:59:56.6823Z",
          "shell.execute_reply": "2021-12-22T19:59:56.71068Z"
        },
        "id": "xx_dREqv2PN7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need to tokenize the tweets using CountVectorizer."
      ],
      "metadata": {
        "id": "BcTBIMKz2PN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = CountVectorizer()\n",
        "X_train_cv =  clf.fit_transform(X_train)\n",
        "X_test_cv = clf.transform(X_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:47.79882Z",
          "iopub.execute_input": "2021-12-22T21:16:47.799076Z",
          "iopub.status.idle": "2021-12-22T21:16:49.887448Z",
          "shell.execute_reply.started": "2021-12-22T21:16:47.799042Z",
          "shell.execute_reply": "2021-12-22T21:16:49.886665Z"
        },
        "trusted": true,
        "id": "-axxWzHB2PN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we create the TF-IDF (term-frequency times inverse document-frequency) versions of the tokenized tweets."
      ],
      "metadata": {
        "id": "r1V99GxZ2PN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_cv)\n",
        "X_train_tf = tf_transformer.transform(X_train_cv)\n",
        "X_test_tf = tf_transformer.transform(X_test_cv)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:49.888669Z",
          "iopub.execute_input": "2021-12-22T21:16:49.890719Z",
          "iopub.status.idle": "2021-12-22T21:16:49.984621Z",
          "shell.execute_reply.started": "2021-12-22T21:16:49.890677Z",
          "shell.execute_reply": "2021-12-22T21:16:49.983725Z"
        },
        "trusted": true,
        "id": "Oww6cpIL2PN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can define the Naive Bayes Classifier model"
      ],
      "metadata": {
        "id": "PoEyrhUl2PN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_clf = MultinomialNB()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:49.985855Z",
          "iopub.execute_input": "2021-12-22T21:16:49.986537Z",
          "iopub.status.idle": "2021-12-22T21:16:49.990851Z",
          "shell.execute_reply.started": "2021-12-22T21:16:49.986496Z",
          "shell.execute_reply": "2021-12-22T21:16:49.989982Z"
        },
        "trusted": true,
        "id": "_I_Dj-uX2PN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_clf.fit(X_train_tf, y_train_le)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:49.992138Z",
          "iopub.execute_input": "2021-12-22T21:16:49.992559Z",
          "iopub.status.idle": "2021-12-22T21:16:50.02363Z",
          "shell.execute_reply.started": "2021-12-22T21:16:49.992487Z",
          "shell.execute_reply": "2021-12-22T21:16:50.022914Z"
        },
        "trusted": true,
        "id": "XEKZXX972PN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_pred = nb_clf.predict(X_test_tf)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:50.025595Z",
          "iopub.execute_input": "2021-12-22T21:16:50.0258Z",
          "iopub.status.idle": "2021-12-22T21:16:50.033226Z",
          "shell.execute_reply.started": "2021-12-22T21:16:50.025776Z",
          "shell.execute_reply": "2021-12-22T21:16:50.032277Z"
        },
        "trusted": true,
        "id": "11uFB5hr2PN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\tClassification Report for Naive Bayes:\\n\\n',classification_report(y_test_le,nb_pred, target_names=['Negative', 'Neutral', 'Positive']))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:50.034928Z",
          "iopub.execute_input": "2021-12-22T21:16:50.035198Z",
          "iopub.status.idle": "2021-12-22T21:16:50.051762Z",
          "shell.execute_reply.started": "2021-12-22T21:16:50.035146Z",
          "shell.execute_reply": "2021-12-22T21:16:50.051035Z"
        },
        "trusted": true,
        "id": "TwFHp36L2PN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The algorithm performance is not so bad. <br> The F1 score is around 70% for the more populated classes (Negative and Positive emotions), and lower for the Neutral class (F1=0.53).<br>\n",
        "In particular, the overall accuracy is 70%.**"
      ],
      "metadata": {
        "id": "jbDdTk6D2PN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next section we will perform the sentiment analysis using BERT."
      ],
      "metadata": {
        "id": "HnrrYG842PN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Sentiment Analysis"
      ],
      "metadata": {
        "id": "MPnz4jXo2PN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We already performed a basic analyis of the tokenized sentences, now we just need to define a custom tokenizer function and call the encode_plus method of the BERT tokenizer."
      ],
      "metadata": {
        "id": "0_bStNA62PN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN=128"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:50.052791Z",
          "iopub.execute_input": "2021-12-22T21:16:50.053144Z",
          "iopub.status.idle": "2021-12-22T21:16:50.057001Z",
          "shell.execute_reply.started": "2021-12-22T21:16:50.053103Z",
          "shell.execute_reply": "2021-12-22T21:16:50.056176Z"
        },
        "trusted": true,
        "id": "j_dnKRmO2PN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(data,max_len=MAX_LEN) :\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for i in range(len(data)):\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            data[i],\n",
        "            add_special_tokens=True,\n",
        "            max_length=MAX_LEN,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "    return np.array(input_ids),np.array(attention_masks)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:50.058416Z",
          "iopub.execute_input": "2021-12-22T21:16:50.058828Z",
          "iopub.status.idle": "2021-12-22T21:16:50.066939Z",
          "shell.execute_reply.started": "2021-12-22T21:16:50.05879Z",
          "shell.execute_reply": "2021-12-22T21:16:50.065741Z"
        },
        "trusted": true,
        "id": "e16cYsK62PN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we apply the tokenizer function to the train, validation and test sets."
      ],
      "metadata": {
        "id": "I8D_Ahd92PN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids, train_attention_masks = tokenize(X_train, MAX_LEN)\n",
        "val_input_ids, val_attention_masks = tokenize(X_valid, MAX_LEN)\n",
        "test_input_ids, test_attention_masks = tokenize(X_test, MAX_LEN)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:16:50.068345Z",
          "iopub.execute_input": "2021-12-22T21:16:50.068739Z",
          "iopub.status.idle": "2021-12-22T21:17:05.894027Z",
          "shell.execute_reply.started": "2021-12-22T21:16:50.068706Z",
          "shell.execute_reply": "2021-12-22T21:17:05.89327Z"
        },
        "trusted": true,
        "id": "nrtn53KP2PN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT modeling"
      ],
      "metadata": {
        "id": "ZCjqT26d2PN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can import the BERT model from the pretrained library from Hugging face."
      ],
      "metadata": {
        "id": "M8_xKYpE2PN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T21:17:05.895409Z",
          "iopub.execute_input": "2021-12-22T21:17:05.89565Z",
          "iopub.status.idle": "2021-12-22T21:17:08.74259Z",
          "shell.execute_reply.started": "2021-12-22T21:17:05.895617Z",
          "shell.execute_reply": "2021-12-22T21:17:08.741859Z"
        },
        "trusted": true,
        "id": "Odu_TtTu2PN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we create a custom function to host the pre trained BERT model, and attach to it a 3 neurons output layer, necessary to perform the classification of the 3 different classes of the dataset (the 3 emotions)."
      ],
      "metadata": {
        "id": "18sXgg2W2PN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(bert_model, max_len=MAX_LEN):\n",
        "\n",
        "    ##params###\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-7)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "    accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "\n",
        "    input_ids = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
        "\n",
        "    attention_masks = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
        "\n",
        "    embeddings = bert_model([input_ids,attention_masks])[1]\n",
        "\n",
        "    output = tf.keras.layers.Dense(3, activation=\"softmax\")(embeddings)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs = [input_ids,attention_masks], outputs = output)\n",
        "\n",
        "    model.compile(opt, loss=loss, metrics=accuracy)\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:17:08.744124Z",
          "iopub.execute_input": "2021-12-22T21:17:08.744637Z",
          "iopub.status.idle": "2021-12-22T21:17:08.752172Z",
          "shell.execute_reply.started": "2021-12-22T21:17:08.744596Z",
          "shell.execute_reply": "2021-12-22T21:17:08.751417Z"
        },
        "trusted": true,
        "id": "hnIXPLQa2PN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(bert_model, MAX_LEN)\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:17:08.753301Z",
          "iopub.execute_input": "2021-12-22T21:17:08.753634Z",
          "iopub.status.idle": "2021-12-22T21:17:10.212279Z",
          "shell.execute_reply.started": "2021-12-22T21:17:08.753596Z",
          "shell.execute_reply": "2021-12-22T21:17:10.211498Z"
        },
        "trusted": true,
        "id": "G-me68-82PN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we can start fine tuning the BERT transformer !"
      ],
      "metadata": {
        "id": "AbyVZO-k2PN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_bert = model.fit([train_input_ids,train_attention_masks], y_train, validation_data=([val_input_ids,val_attention_masks], y_valid), epochs=4, batch_size=32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T21:17:10.21337Z",
          "iopub.execute_input": "2021-12-22T21:17:10.213855Z",
          "iopub.status.idle": "2021-12-22T22:06:54.439353Z",
          "shell.execute_reply.started": "2021-12-22T21:17:10.213816Z",
          "shell.execute_reply": "2021-12-22T22:06:54.438631Z"
        },
        "trusted": true,
        "id": "2DshggnB2PN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT results"
      ],
      "metadata": {
        "id": "0uli4Uq82PN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_bert = model.predict([test_input_ids,test_attention_masks])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T22:06:54.441058Z",
          "iopub.execute_input": "2021-12-22T22:06:54.441322Z",
          "iopub.status.idle": "2021-12-22T22:07:16.077636Z",
          "shell.execute_reply.started": "2021-12-22T22:06:54.441287Z",
          "shell.execute_reply": "2021-12-22T22:07:16.076752Z"
        },
        "trusted": true,
        "id": "zmgkAkJm2PN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_bert =  np.zeros_like(result_bert)\n",
        "y_pred_bert[np.arange(len(y_pred_bert)), result_bert.argmax(1)] = 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T22:07:16.081165Z",
          "iopub.execute_input": "2021-12-22T22:07:16.081513Z",
          "iopub.status.idle": "2021-12-22T22:07:16.087746Z",
          "shell.execute_reply.started": "2021-12-22T22:07:16.081482Z",
          "shell.execute_reply": "2021-12-22T22:07:16.087002Z"
        },
        "trusted": true,
        "id": "yu9uism52PN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix(y_test.argmax(1), y_pred_bert.argmax(1),'BERT Sentiment Analysis\\nConfusion Matrix')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T22:07:16.089167Z",
          "iopub.execute_input": "2021-12-22T22:07:16.089448Z",
          "iopub.status.idle": "2021-12-22T22:07:16.318816Z",
          "shell.execute_reply.started": "2021-12-22T22:07:16.089414Z",
          "shell.execute_reply": "2021-12-22T22:07:16.318033Z"
        },
        "trusted": true,
        "id": "zGfjPCbU2PN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\tClassification Report for BERT:\\n\\n',classification_report(y_test,y_pred_bert, target_names=['Negative', 'Neutral', 'Positive']))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T22:07:16.31994Z",
          "iopub.execute_input": "2021-12-22T22:07:16.320692Z",
          "iopub.status.idle": "2021-12-22T22:07:16.345718Z",
          "shell.execute_reply.started": "2021-12-22T22:07:16.320653Z",
          "shell.execute_reply": "2021-12-22T22:07:16.345014Z"
        },
        "trusted": true,
        "id": "nKqByWXL2PN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RoBERTa Sentiment Analysis"
      ],
      "metadata": {
        "id": "kRHsrwph2PN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen for BERT, we first import the tokenizer used to train the original roberta transformer by Facebook."
      ],
      "metadata": {
        "id": "9CbjM8Qv2PN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_roberta = RobertaTokenizerFast.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T22:08:43.116218Z",
          "iopub.execute_input": "2021-12-22T22:08:43.116667Z",
          "iopub.status.idle": "2021-12-22T22:08:50.649025Z",
          "shell.execute_reply.started": "2021-12-22T22:08:43.116627Z",
          "shell.execute_reply": "2021-12-22T22:08:50.648287Z"
        },
        "trusted": true,
        "id": "09H_1_Zo2PN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we check the length of the longest tokenized sentence by roberta tokenizer:"
      ],
      "metadata": {
        "id": "2cznwqnY2PN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in X_train:\n",
        "    tokens = tokenizer_roberta.encode(txt, max_length=512, truncation=True)\n",
        "    token_lens.append(len(tokens))\n",
        "max_length=np.max(token_lens)\n",
        "max_length"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T22:08:50.651296Z",
          "iopub.execute_input": "2021-12-22T22:08:50.651554Z",
          "iopub.status.idle": "2021-12-22T22:09:00.109456Z",
          "shell.execute_reply.started": "2021-12-22T22:08:50.651524Z",
          "shell.execute_reply": "2021-12-22T22:09:00.108622Z"
        },
        "trusted": true,
        "id": "02O8RNhR2PN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN=128"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T22:09:00.110918Z",
          "iopub.execute_input": "2021-12-22T22:09:00.111182Z",
          "iopub.status.idle": "2021-12-22T22:09:00.11522Z",
          "shell.execute_reply.started": "2021-12-22T22:09:00.111146Z",
          "shell.execute_reply": "2021-12-22T22:09:00.114446Z"
        },
        "trusted": true,
        "id": "kcYF1eTj2PN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can define the tokenization function"
      ],
      "metadata": {
        "id": "P8u9V_t12PN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_roberta(data,max_len=MAX_LEN) :\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for i in range(len(data)):\n",
        "        encoded = tokenizer_roberta.encode_plus(\n",
        "            data[i],\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "    return np.array(input_ids),np.array(attention_masks)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T22:09:00.117509Z",
          "iopub.execute_input": "2021-12-22T22:09:00.11775Z",
          "iopub.status.idle": "2021-12-22T22:09:00.126043Z",
          "shell.execute_reply.started": "2021-12-22T22:09:00.117704Z",
          "shell.execute_reply": "2021-12-22T22:09:00.125367Z"
        },
        "trusted": true,
        "id": "fKnqVqg_2PN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids, train_attention_masks = tokenize_roberta(X_train, MAX_LEN)\n",
        "val_input_ids, val_attention_masks = tokenize_roberta(X_valid, MAX_LEN)\n",
        "test_input_ids, test_attention_masks = tokenize_roberta(X_test, MAX_LEN)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T22:09:00.12842Z",
          "iopub.execute_input": "2021-12-22T22:09:00.128657Z",
          "iopub.status.idle": "2021-12-22T22:09:16.271659Z",
          "shell.execute_reply.started": "2021-12-22T22:09:00.128626Z",
          "shell.execute_reply": "2021-12-22T22:09:16.270814Z"
        },
        "trusted": true,
        "id": "CTv_mT_I2PN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RoBERTa modeling"
      ],
      "metadata": {
        "id": "qnW0CXvL2POA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(bert_model, max_len=MAX_LEN):\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-7)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "    accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "    input_ids = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
        "    attention_masks = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
        "    output = bert_model([input_ids,attention_masks])\n",
        "    output = output[1]\n",
        "    output = tf.keras.layers.Dense(3, activation=tf.nn.softmax)(output)\n",
        "    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n",
        "    model.compile(opt, loss=loss, metrics=accuracy)\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T22:09:16.275223Z",
          "iopub.execute_input": "2021-12-22T22:09:16.27546Z",
          "iopub.status.idle": "2021-12-22T22:09:16.282419Z",
          "shell.execute_reply.started": "2021-12-22T22:09:16.275433Z",
          "shell.execute_reply": "2021-12-22T22:09:16.28167Z"
        },
        "trusted": true,
        "id": "LJHU5Dvz2POA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roberta_model = TFRobertaModel.from_pretrained('roberta-base')"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T22:09:16.283698Z",
          "iopub.execute_input": "2021-12-22T22:09:16.284104Z",
          "iopub.status.idle": "2021-12-22T22:09:19.200534Z",
          "shell.execute_reply.started": "2021-12-22T22:09:16.284069Z",
          "shell.execute_reply": "2021-12-22T22:09:19.198861Z"
        },
        "trusted": true,
        "id": "A8acm6Ts2POA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(roberta_model, MAX_LEN)\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T22:09:19.203061Z",
          "iopub.execute_input": "2021-12-22T22:09:19.203495Z",
          "iopub.status.idle": "2021-12-22T22:09:21.496134Z",
          "shell.execute_reply.started": "2021-12-22T22:09:19.203453Z",
          "shell.execute_reply": "2021-12-22T22:09:21.495426Z"
        },
        "trusted": true,
        "id": "fcd0eYlx2POA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_2 = model.fit([train_input_ids,train_attention_masks], y_train, validation_data=([val_input_ids,val_attention_masks], y_valid), epochs=4, batch_size=30)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T22:09:21.497524Z",
          "iopub.execute_input": "2021-12-22T22:09:21.497782Z",
          "iopub.status.idle": "2021-12-22T23:01:57.16071Z",
          "shell.execute_reply.started": "2021-12-22T22:09:21.497746Z",
          "shell.execute_reply": "2021-12-22T23:01:57.159908Z"
        },
        "trusted": true,
        "id": "U1N9qZVY2POA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RoBERTa results"
      ],
      "metadata": {
        "id": "T9MdxijX2POA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_roberta = model.predict([test_input_ids,test_attention_masks])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T23:01:57.162528Z",
          "iopub.execute_input": "2021-12-22T23:01:57.162787Z",
          "iopub.status.idle": "2021-12-22T23:02:18.816734Z",
          "shell.execute_reply.started": "2021-12-22T23:01:57.162754Z",
          "shell.execute_reply": "2021-12-22T23:02:18.815967Z"
        },
        "trusted": true,
        "id": "DbtkG_lH2POA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_roberta =  np.zeros_like(result_roberta)\n",
        "y_pred_roberta[np.arange(len(y_pred_roberta)), result_roberta.argmax(1)] = 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-22T23:02:18.818471Z",
          "iopub.execute_input": "2021-12-22T23:02:18.818725Z",
          "iopub.status.idle": "2021-12-22T23:02:18.824354Z",
          "shell.execute_reply.started": "2021-12-22T23:02:18.818691Z",
          "shell.execute_reply": "2021-12-22T23:02:18.823634Z"
        },
        "trusted": true,
        "id": "7RAtGXmj2POB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix(y_test.argmax(1),y_pred_roberta.argmax(1),'RoBERTa Sentiment Analysis\\nConfusion Matrix')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T23:02:18.826277Z",
          "iopub.execute_input": "2021-12-22T23:02:18.826841Z",
          "iopub.status.idle": "2021-12-22T23:02:19.069944Z",
          "shell.execute_reply.started": "2021-12-22T23:02:18.826804Z",
          "shell.execute_reply": "2021-12-22T23:02:19.069179Z"
        },
        "trusted": true,
        "id": "6U06wUus2POB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\tClassification Report for RoBERTa:\\n\\n',classification_report(y_test,y_pred_roberta, target_names=['Negative', 'Neutral', 'Positive']))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T23:02:19.071175Z",
          "iopub.execute_input": "2021-12-22T23:02:19.071621Z",
          "iopub.status.idle": "2021-12-22T23:02:19.09548Z",
          "shell.execute_reply.started": "2021-12-22T23:02:19.071583Z",
          "shell.execute_reply": "2021-12-22T23:02:19.094654Z"
        },
        "trusted": true,
        "id": "QAjJ6Uut2POB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results Summary"
      ],
      "metadata": {
        "id": "AYu3rXFz2POB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Classification Report"
      ],
      "metadata": {
        "id": "HT6X_bov2POB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Classification Report for BERT:\\n',classification_report(y_test,y_pred_bert, target_names=['Negative', 'Neutral', 'Positive']))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T23:03:50.712012Z",
          "iopub.execute_input": "2021-12-22T23:03:50.712282Z",
          "iopub.status.idle": "2021-12-22T23:03:50.73796Z",
          "shell.execute_reply.started": "2021-12-22T23:03:50.712244Z",
          "shell.execute_reply": "2021-12-22T23:03:50.737074Z"
        },
        "trusted": true,
        "id": "hJnDlDKW2POB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RoBERTa Classification Report"
      ],
      "metadata": {
        "id": "_-sOaoNB2POB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Classification Report for RoBERTa:\\n',classification_report(y_test,y_pred_roberta, target_names=['Negative', 'Neutral', 'Positive']))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T23:03:51.065166Z",
          "iopub.execute_input": "2021-12-22T23:03:51.065429Z",
          "iopub.status.idle": "2021-12-22T23:03:51.088265Z",
          "shell.execute_reply.started": "2021-12-22T23:03:51.065394Z",
          "shell.execute_reply": "2021-12-22T23:03:51.087556Z"
        },
        "trusted": true,
        "id": "uO6eIKCb2POB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Matrix Comparison"
      ],
      "metadata": {
        "id": "OM2mRelL2POB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(9,5.5))\n",
        "\n",
        "labels = ['Negative', 'Neutral', 'Positive']\n",
        "plt.suptitle('Sentiment Analysis Comparison\\n Confusion Matrix', fontsize=20)\n",
        "\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test.argmax(1),y_pred_bert.argmax(1)), annot=True, cmap=\"Blues\", fmt='g', cbar=False, ax=ax[0], annot_kws={\"size\":25})\n",
        "\n",
        "ax[0].set_title('BERT Classifier', fontsize=20)\n",
        "ax[0].set_yticklabels(labels, fontsize=17);\n",
        "ax[0].set_xticklabels(labels, fontsize=17);\n",
        "ax[0].set_ylabel('Test', fontsize=20)\n",
        "ax[0].set_xlabel('Predicted', fontsize=20)\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test.argmax(1),y_pred_roberta.argmax(1)), annot=True, cmap=\"Blues\", fmt='g', cbar=False, ax=ax[1], annot_kws={\"size\":25})\n",
        "ax[1].set_title('RoBERTa Classifier', fontsize=20)\n",
        "ax[1].set_yticklabels(labels, fontsize=17);\n",
        "ax[1].set_xticklabels(labels, fontsize=17);\n",
        "ax[1].set_ylabel('Test', fontsize=20)\n",
        "ax[1].set_xlabel('Predicted', fontsize=20)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-22T23:03:51.670252Z",
          "iopub.execute_input": "2021-12-22T23:03:51.670767Z",
          "iopub.status.idle": "2021-12-22T23:03:52.085682Z",
          "shell.execute_reply.started": "2021-12-22T23:03:51.670727Z",
          "shell.execute_reply": "2021-12-22T23:03:52.084962Z"
        },
        "trusted": true,
        "id": "eIS6U4j32POC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that both the algorithms performed well on the classification task, with performance scores around 90%."
      ],
      "metadata": {
        "id": "xtTlFf4z2POC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thank you for reading my notebook!! Let me know if you have any question or if you want me to check out your works !! :)**"
      ],
      "metadata": {
        "id": "JzrzZRoH2POC"
      }
    }
  ]
}